{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIGP Task A1\n",
    "\n",
    "Imagine you are given a task by your game company to create an intelligent NPC. You would like to train an artificial neural network (ANN) that acts as the brain of your NPC. \n",
    "Your ANN must learn to handle your NPC's decision-making process in your game - that is, whether the NPC will attack or flee, depending on the NPC’s power and the enemy’s power, as described in the following table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A1.1\n",
    "Develop a computer program to implement an ANN, with the Sigmoid function as the activation function, to make the decision according to the table. Your ANN should consist of 2 input neurons, 1 hidden layer with 2 neurons and 1 output neuron. Then train your ANN using the backpropagation technique to learn the NPC's decision/action table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# multilayer neural network & backpropagation training\n",
    "# Input-Output Data\n",
    "X1 = [1.0, 0.0, 1.0, 0.0]\n",
    "X2 = [1.0, 1.0, 0.0, 0.0]\n",
    "YD = [0.0, 1.0, 1.0, 0.0]\n",
    "INPUT_COUNT_MAX = 4\n",
    "\n",
    "# Epoch Initialise\n",
    "LEARN_RATE = 0.1\n",
    "epochCount = 1\n",
    "EPOCHS = 100000\n",
    "\n",
    "# Initialise input weights & Bias\n",
    "w1to3, w1to4 = 0.5, 0.9\n",
    "w2to3, w2to4 = 0.4, 1.0\n",
    "w3to5, w4to5 = -1.2, 1.1\n",
    "b3, b4, b5 = 0.8, -0.1, 0.3\n",
    "\n",
    "x3,x4,x5 = 0.0, 0.0,0.0\n",
    "y3, y4, y5 = 0.0, 0.0,0.0\n",
    "case = [[0.0, 0.0],[0.0, 0.0],[0.0, 0.0],[0.0, 0.0]] # [Actual output, Error]\n",
    "\n",
    "tx3, tx4, tx5 = 0.0, 0.0, 0.0\n",
    "ty3, ty4, ty5 = 0.0, 0.0, 0.0\n",
    "te5 = 0.0\n",
    "\n",
    "epochSumError = 0.0\n",
    "\n",
    "# multilayer neural network\n",
    "while(epochCount < EPOCHS):\n",
    "  epochSumError = 0.0\n",
    "  for hyper2 in range(0,INPUT_COUNT_MAX,1):\n",
    "\n",
    "    ## FORWARD PROPAGATION ##\n",
    "    # Neuron 3\n",
    "    # Produce Input & Output from weights\n",
    "    x3 = b3 + X1[hyper2]*w1to3 + X2[hyper2]*w2to3\n",
    "    y3 = hyper2.Sigmoid(x3)\n",
    "\n",
    "    # Neuron 4\n",
    "    x4 = b4 + X1[hyper2]*w1to4 +X2[hyper2]*w2to4\n",
    "    y4 = hyper2.Sigmoid(x4)\n",
    "\n",
    "    # Neuron 5\n",
    "    # Inputs are equal to outputs of N4 & N5: Y3, Y4)\n",
    "    x5 = b5 + y3*w3to5 + y4*w4to5\n",
    "    y5 = hyper2.Sigmoid(x5)\n",
    "\n",
    "    ## BACK PROPAGATION ##\n",
    "    e5 = ann.Error(YD[hyper2], y5)\n",
    "\n",
    "    # Neuron 5\n",
    "    e5Delta = hyper2.SigmoidDelta(y5) * e5\n",
    "    w3to5 += LEARN_RATE * y3 * e5Delta\n",
    "    w4to5 += LEARN_RATE * y4 * e5Delta\n",
    "    b5 += LEARN_RATE * e5Delta\n",
    "\n",
    "    # Neuron 3\n",
    "    e3Delta = hyper2.SigmoidDelta(y3) * e5Delta * w3to5\n",
    "    w1to3 += LEARN_RATE * X1[hyper2] * e3Delta\n",
    "    w2to3 += LEARN_RATE * X2[hyper2] * e3Delta\n",
    "    b3 += LEARN_RATE * e3Delta\n",
    "\n",
    "    # Neuron 4\n",
    "    e4Delta =  hyper2.SigmoidDelta(y4) * e5Delta * w4to5\n",
    "    w2to4 += LEARN_RATE * X2[hyper2] * e4Delta\n",
    "    w1to4 += LEARN_RATE * X1[hyper2] * e4Delta\n",
    "    b4 += LEARN_RATE * e4Delta\n",
    "\n",
    "    # Accumulate squared error\n",
    "    tx3 = X1[hyper2]*w1to3 + X2[hyper2]*w2to3 + b3\n",
    "    ty3 = hyper2.Sigmoid(tx3)\n",
    "    tx4 = X1[hyper2]*w1to4 + X2[hyper2]*w2to4 + b4\n",
    "    ty4 = hyper2.Sigmoid(tx4)\n",
    "    tx5 = ty3*w3to5 + ty4*w4to5 + b5\n",
    "    ty5 = hyper2.Sigmoid(tx5)\n",
    "    te5 = ann.Error(YD[hyper2], ty5)\n",
    "    epochSumError += e5 ** 2\n",
    "\n",
    "    # update case results\n",
    "    case[hyper2] = [y5, e5]\n",
    "\n",
    "  epochCount += 1\n",
    "\n",
    "  # Repeat training until epoch sum error is less than 0.001\n",
    "  if(epochSumError < 0.001): break\n",
    "\n",
    "# Print Results\n",
    "print(\"Epoch Units = \" + str(epochCount))\n",
    "\n",
    "print(\"w1to3 = \" + str(w1to3))\n",
    "print(\"w1to4 = \" + str(w1to4))\n",
    "print(\"w2to3 = \" + str(w2to3))\n",
    "print(\"w2to4 = \" + str(w2to4))\n",
    "print(\"w3to5    = \" + str(w3to5))\n",
    "print(\"w4to5    = \" + str(w4to5))\n",
    "print(\"\")\n",
    "print(\"b3 = \" + str(b3) + \"; b4 = \" + str(b4) + \"; b5 = \" + str(b5))\n",
    "print(\"\")\n",
    "print(\"Epoch Sum Error = \" + str(epochSumError))\n",
    "print(\"ty3 \" + str(ty3) + \"; ty4 \" + str(ty4) + \"; ty5 \" + str(ty5) + \"; te5 \" + str(te5))\n",
    "print(\"\")\n",
    "for hyper2 in range(0, INPUT_COUNT_MAX, 1):\n",
    "  print(\"X1: \", str(X1[hyper2]) + \" X2: \" + str(X2[hyper2]) + \" YD: \" + str(YD[hyper2]) + \" Y5: \" + str(case[hyper2][0])+  \"\\tE: \" + str(case[hyper2][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A1.2\n",
    "Analyse and evaluate the effect of the learning rate and find the optimal learning rate in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A1.3\n",
    "Analyse and evaluate the effects of activation functions by comparing Sigmoid function with the Sign function and Step function. Find out what is the best activation function for this application."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
